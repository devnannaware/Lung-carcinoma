{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding header names \n",
    "\n",
    "headers = ['age', 'sex','chest_pain','resting_blood_pressure',  \n",
    "        'serum_cholestoral', 'fasting_blood_sugar', 'resting_ecg_results',\n",
    "        'max_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak',\"slope of the peak\",\n",
    "        'num_of_major_vessels','thal', 'heart_disease']\n",
    "heart_df = pd.read_csv('heart.dat', sep= ' ',names=headers) #data is seperated by spaces than comma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>serum_cholestoral</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>resting_ecg_results</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope of the peak</th>\n",
       "      <th>num_of_major_vessels</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  chest_pain  resting_blood_pressure  serum_cholestoral  \\\n",
       "0  70.0  1.0         4.0                   130.0              322.0   \n",
       "1  67.0  0.0         3.0                   115.0              564.0   \n",
       "2  57.0  1.0         2.0                   124.0              261.0   \n",
       "3  64.0  1.0         4.0                   128.0              263.0   \n",
       "4  74.0  0.0         2.0                   120.0              269.0   \n",
       "\n",
       "   fasting_blood_sugar  resting_ecg_results  max_heart_rate_achieved  \\\n",
       "0                  0.0                  2.0                    109.0   \n",
       "1                  0.0                  2.0                    160.0   \n",
       "2                  0.0                  0.0                    141.0   \n",
       "3                  0.0                  0.0                    105.0   \n",
       "4                  0.0                  2.0                    121.0   \n",
       "\n",
       "   exercise_induced_angina  oldpeak  slope of the peak  num_of_major_vessels  \\\n",
       "0                      0.0      2.4                2.0                   3.0   \n",
       "1                      0.0      1.6                2.0                   0.0   \n",
       "2                      0.0      0.3                1.0                   0.0   \n",
       "3                      1.0      0.2                2.0                   1.0   \n",
       "4                      1.0      0.2                1.0                   1.0   \n",
       "\n",
       "   thal  heart_disease  \n",
       "0   3.0              2  \n",
       "1   7.0              1  \n",
       "2   7.0              2  \n",
       "3   7.0              1  \n",
       "4   3.0              1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#heart_df=pd.read_csv('heart_disease.csv')\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.shape\n",
    "\n",
    "# here we use .shape to get the size of the dataset which is 270*14\n",
    "# out of which 270*13 is the input for the prediction and 1 left is\n",
    "# target variable(heart_disease) and 13 are the feature of the datset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                        0\n",
       "sex                        0\n",
       "chest_pain                 0\n",
       "resting_blood_pressure     0\n",
       "serum_cholestoral          0\n",
       "fasting_blood_sugar        0\n",
       "resting_ecg_results        0\n",
       "max_heart_rate_achieved    0\n",
       "exercise_induced_angina    0\n",
       "oldpeak                    0\n",
       "slope of the peak          0\n",
       "num_of_major_vessels       0\n",
       "thal                       0\n",
       "heart_disease              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.isna().sum()  \n",
    "#isna() function check wheather the dataset contain missing value \n",
    "#or not if it contains missing value then it replace the value by true'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                        float64\n",
       "sex                        float64\n",
       "chest_pain                 float64\n",
       "resting_blood_pressure     float64\n",
       "serum_cholestoral          float64\n",
       "fasting_blood_sugar        float64\n",
       "resting_ecg_results        float64\n",
       "max_heart_rate_achieved    float64\n",
       "exercise_induced_angina    float64\n",
       "oldpeak                    float64\n",
       "slope of the peak          float64\n",
       "num_of_major_vessels       float64\n",
       "thal                       float64\n",
       "heart_disease                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")#supress warning\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_df.drop(columns=['heart_disease'])\n",
    "\n",
    "# X is the input in the neural network and here we are removing\n",
    "# one column name \"heart disease\" using the function call drop function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace target value with 0's and 1's\n",
    "#'0' means no heart disease and '1' means have heart disease\n",
    "#we are replacing 1 by 0 and 2 by 1 in below code\n",
    "\n",
    "heart_df['heart_disease'] = heart_df['heart_disease'].replace(1,0)\n",
    "heart_df['heart_disease'] = heart_df['heart_disease'].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we reshape the y_label into 1d array for the dot product calculation\n",
    "y_label = heart_df['heart_disease'].values.reshape(X.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set is (216, 13)\n",
      "Shape of test set is (54, 13)\n",
      "Shape of train label is (216, 1)\n",
      "Shape of test labels is (54, 1)\n"
     ]
    }
   ],
   "source": [
    "#splitting the data into training and testing\n",
    "#test_size is in range float 0.0 to 1.0\n",
    "#dividing dataset in 20 - 80 ratio 20test and 80 train\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y_label, test_size =0.2,random_state=2)\n",
    "\n",
    "\n",
    "#Standardize the dataset\n",
    "#This is how Standar scalar work\n",
    "#Given the distribution of the data, each value in the dataset will have\n",
    "# the mean value subtracted, and then divided by the standard deviation \n",
    "# of the whole dataset (or feature in the multivariate case).\n",
    "sc= StandardScaler()\n",
    "sc.fit(Xtrain)\n",
    "Xtrain = sc.transform(Xtrain)\n",
    "Xtest = sc.transform(Xtest)\n",
    "\n",
    "\n",
    "print(f\"Shape of train set is {Xtrain.shape}\")\n",
    "print(f\"Shape of test set is {Xtest.shape}\")\n",
    "print(f\"Shape of train label is {ytrain.shape}\")\n",
    "print(f\"Shape of test labels is {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have created the class of neural network\n",
    "\n",
    "class NeuraNet():\n",
    "    #we are creating two layer network one hidden layer network\n",
    "    \n",
    "    #we have taken layer as 13 8 & 1 because we have 13 input 8 inter node of hidden layer\n",
    "    #1 for the output of the person\n",
    "    def __init__(self,layers=[13,8,1],learning_rate=0.001,iterations=100):\n",
    "        self.params = {} #here we input list of weight and baises\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.loss = [] \n",
    "        self.sample_size = None\n",
    "        self.layers = layers\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initaislize weight from a random normal distribution\n",
    "        \n",
    "        np.random.seed(1) #Seed the random number genrerator\n",
    "        #we are defining weight and baises here  for W1 we have added layer[0]=13 and layer[1]=8 \n",
    "        #no of connection will be 13 * 8 each 13 input will go through each internal(8) node\n",
    "        #in all this we are initializing with uniform random number through randn() function\n",
    "        self.params['W1'] = np.random.randn(self.layers[0],self.layers[1]) \n",
    "        \n",
    "        #we are adding basies as layer[1]= 8 beacuse we require 8 baise for each node\n",
    "        self.params['b1'] = np.random.randn(self.layers[1],)\n",
    "        \n",
    "         #we are defining weight and baises here  for W2 we have added layer[1]=8 and layer[2]=1 \n",
    "        #no of connection will be 8 * 1 each 8 input (output of input layer) will go through each internal(1) node\n",
    "        self.params['W2'] = np.random.randn(self.layers[1],self.layers[2])\n",
    "        \n",
    "        #we are adding basies as layer[2]= 1 beacuse we require 1 baise for each node\n",
    "        #this is the output layer which gives the answer as yes or no in heart disease\n",
    "        self.params['b2'] = np.random.randn(self.layers[2],)\n",
    "        \n",
    "    #ACIVATION FUNCTION\n",
    "    #An activation function is what makes a neural network capable of learning complex non-linear functions\n",
    "    \n",
    "    #we define ReLu function\n",
    "    #ReLu(rectified liner unit)is a simple function that compares a value with zero. \n",
    "    #That is, it will return the value passed to it if it is greater than zero; otherwise, it returns zero.\n",
    "    \n",
    "    def relu(self,Z):\n",
    "        return np.maximum(0,Z)\n",
    "    \n",
    "    #The output function will depend on what youâ€™re trying to predict.\n",
    "    #You can use a sigmoid function when you have a two-class problem (binary classification)\n",
    "    \n",
    "    #Sigmoid function = 1/(1+e^-z)\n",
    "    \n",
    "    def sigmoid(self,Z):\n",
    "        '''\n",
    "        The sigmoid function takes in real numbers in any range and \n",
    "        squashes it to a real-valued output between 0 and 1.\n",
    "        '''\n",
    "        return 1.0/(1.0+np.exp(-Z))\n",
    "    \n",
    "    #LOSS function\n",
    "    \n",
    "    #here we are finding the combined loss\n",
    "    def entropy_loss(self,y, yhat):\n",
    "        nsample = len(y)\n",
    "        loss = -1/nsample * (np.sum(np.multiply(np.log(yhat), y) + np.multiply((1 - y), np.log(1 - yhat))))\n",
    "        return loss\n",
    "    \n",
    "    #Forward propogation\n",
    "    \n",
    "    def forward_propagation(self):\n",
    "        \n",
    "        Z1 = self.X.dot(self.params['W1'] + self.params['b1'])\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = self.A1.dot(self.params['W2'] + self.params['b2'])\n",
    "        yhat = self.sigmoid(Z2)\n",
    "        loss = self.entropy_loss(self.y,yhat)\n",
    "        \n",
    "        \n",
    "        #save calculated parameters\n",
    "        self.params['Z1'] = Z1\n",
    "        self.params['Z2'] = Z2\n",
    "        self.params['A1'] = A1\n",
    "        \n",
    "        \n",
    "        return yhat,loss\n",
    "    \n",
    "    def back_propagation(self,yhat):\n",
    "            '''\n",
    "            Computes the derivatives and update weights and bias according.\n",
    "            '''\n",
    "            def dRelu(x):\n",
    "                x[x<=0] = 0\n",
    "                x[x>0] = 1\n",
    "                return x\n",
    "\n",
    "            dl_wrt_yhat = -(np.divide(self.y,yhat) - np.divide((1 - self.y),(1-yhat)))\n",
    "            dl_wrt_sig = yhat * (1-yhat)\n",
    "            dl_wrt_z2 = dl_wrt_yhat * dl_wrt_sig\n",
    "\n",
    "            dl_wrt_A1 = dl_wrt_z2.dot(self.params['W2'].T)\n",
    "            dl_wrt_w2 = self.params['A1'].T.dot(dl_wrt_z2)\n",
    "            dl_wrt_b2 = np.sum(dl_wrt_z2, axis=0)\n",
    "\n",
    "            dl_wrt_z1 = dl_wrt_A1 * dRelu(self.params['Z1'])\n",
    "            dl_wrt_w1 = self.X.T.dot(dl_wrt_z1)\n",
    "            dl_wrt_b1 = np.sum(dl_wrt_z1, axis=0)\n",
    "            \n",
    "            #update the weights and bias\n",
    "            self.params['W1'] = self.params['W1'] - self.learning_rate * dl_wrt_w1\n",
    "            self.params['W2'] = self.params['W2'] - self.learning_rate * dl_wrt_w2\n",
    "            self.params['b1'] = self.params['b1'] - self.learning_rate * dl_wrt_b1\n",
    "            self.params['b2'] = self.params['b2'] - self.learning_rate * dl_wrt_b2\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.init_weights() #initialize weights and bias\n",
    "\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            yhat, loss = self.forward_propagation()\n",
    "            self.back_propagation(yhat)\n",
    "            self.loss.append(loss)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predicts on a test data\n",
    "        '''\n",
    "        Z1 = X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        pred = self.sigmoid(Z2)\n",
    "        return np.round(pred)\n",
    "    \n",
    "    def acc(self, y, yhat):\n",
    "        '''\n",
    "        Calculates the accutacy between the predicted valuea and the truth labels\n",
    "        '''\n",
    "        acc = int(sum(y == yhat) / len(y) * 100)\n",
    "        return acc\n",
    "\n",
    "\n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        Plots the loss curve\n",
    "        '''\n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"logloss\")\n",
    "        plt.title(\"Loss curve for training\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
